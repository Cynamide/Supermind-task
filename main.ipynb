{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Arjit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Arjit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Arjit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Arjit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import lda\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_scrapped.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeFimillion</td>\n",
       "      <td>‚õè To succeed where others have failed! To lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VerifiedCryptoNews</td>\n",
       "      <td>BITCOIN Update: BTCUSDT - H4 chart. Date: 29th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>universalcryptosignals</td>\n",
       "      <td>Follow us on tradingview for daily upto 10 fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altsignals</td>\n",
       "      <td>**You struggled with these fake and eye catchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mycryptopedia</td>\n",
       "      <td>**ü§£ Meme of the Week ü§£** **üëâTIP OF THE DAY**üëà...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>btcchamp</td>\n",
       "      <td>üíé`STYLIKE by FASHION` `TVüíé  üì≤A web3 fashion ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>onwardbtc_official</td>\n",
       "      <td>https://youtu.be/eetgnDcHku8 https://youtu.be/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    group                                               text\n",
       "0             DeFimillion  ‚õè To succeed where others have failed! To lead...\n",
       "1      VerifiedCryptoNews  BITCOIN Update: BTCUSDT - H4 chart. Date: 29th...\n",
       "2  universalcryptosignals  Follow us on tradingview for daily upto 10 fre...\n",
       "3              altsignals  **You struggled with these fake and eye catchi...\n",
       "4           mycryptopedia   **ü§£ Meme of the Week ü§£** **üëâTIP OF THE DAY**üëà...\n",
       "5                btcchamp  üíé`STYLIKE by FASHION` `TVüíé  üì≤A web3 fashion ap...\n",
       "6      onwardbtc_official  https://youtu.be/eetgnDcHku8 https://youtu.be/..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = set(stopwords.words('english'))\n",
    "## load stopwords.txt and add to ignore\n",
    "with open('stopwords.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        ignore.add(line.strip())\n",
    "        \n",
    "tokenizer = RegexpTokenizer(r'\\w+')  # remove punctuation and emojis from text\n",
    "stemmer = WordNetLemmatizer()  # lemmatize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26845/26845 [00:01<00:00, 16567.10it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 181664/181664 [00:00<00:00, 192601.06it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90492/90492 [00:00<00:00, 193307.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167932/167932 [00:00<00:00, 183488.74it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 124026/124026 [00:00<00:00, 189306.79it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47639/47639 [00:00<00:00, 185323.66it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62334/62334 [00:00<00:00, 211248.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text data (can be improved)\n",
    "text = []\n",
    "for i in range(len(data)):\n",
    "    stemmed = []\n",
    "    words = tokenizer.tokenize(data[i])\n",
    "    for word in tqdm(words):\n",
    "        word = re.sub(r'\\d+', '', word)\n",
    "        word = word.strip()\n",
    "        if word[:4] == 'box_' or word[:2] == '0x':\n",
    "            continue\n",
    "        if word not in ignore:\n",
    "            stemmed.append(stemmer.lemmatize(word))\n",
    "    text.append(' '.join(stemmed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing N-grams from 1 to 2 i.e. unigrams and bigrams\n",
    "vec = CountVectorizer(analyzer='word', ngram_range=(1, 2)) \n",
    "X = vec.fit_transform(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', n_components=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 topic\n",
    "model = LatentDirichletAllocation(n_components=1,learning_method='online') \n",
    "model.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = model.exp_dirichlet_component_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 500 # Top 500 words to display for topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['profit' 'target' 'btc' 'binance' 'usdt' 'profit target' 'period'\n",
      " 'minutes' 'profit period' 'hours' 'hours minutes' 'take' 'take profit'\n",
      " 'target profit' 'bitcoin' 'period hours' 'futures' 'binance futures'\n",
      " 'usdt take' 'we' 'bybit' 'market' 'crypto' 'bitmex' 'buy' 'the' 'price'\n",
      " 'join' 'eth' 'trade' 'minutes binance' 'trading' 'marketcap' 'get' 'days'\n",
      " 'days hours' 'signal' 'all' 'period days' 'support' 'volume' 'vip'\n",
      " 'channel' 'sell' 'btc usdt' 'time' 'achieved' 'stop' 'target achieved'\n",
      " 'tradingview' 'hit' 'achieved profit' 'all profit' 'loss' 'also' 'usd'\n",
      " 'bybit usdt' 'bittrex' 'update' 'token' 'resistance' 'xrp' 'leverage'\n",
      " 'this' 'one' 'short' 'io' 'ltc' 'term' 'post' 'good' 'long' 'bch' 'week'\n",
      " 'verifiedcryptonews' 'month' 'exchange' 'eos' 'free' 'target target'\n",
      " 'dominance' 'usdt all' 'level' 'it' 'btc usd' 'first' 'coin' 'still'\n",
      " 'altsignals' 'stop loss' 'premium' 'kucoin' 'change' 'if' 'news' 'next'\n",
      " 'ada' 'chart' 'today' 'last' 'buy sell' 'blockchain' 'go' 'old'\n",
      " 'cryptocurrency' 'you' 'link' 'high' 'reached' 'bitcoin dominance' 'bot'\n",
      " 'summary' 'xlm' 'bullish' 'zone' 'usd take' 'btc eth' 'discount' 'in'\n",
      " 'entry' 'like' 'summary btc' 'our' 'topcoins summary' 'topcoins'\n",
      " 'volume topcoins' 'may' 'member' 'old marketcap' 'telegram'\n",
      " 'marketcap post' 'minutes bybit' 'btc take' 'bnb' 'year' 'analysis'\n",
      " 'minutes bitmex' 'start' 'profit leverage' 'eth xrp' 'for'\n",
      " 'period minutes' 'bitmex bybit' 'would' 'medium' 'onwardbtc'\n",
      " 'futures btc' 'now' 'usdt binance' 'current' 'break' 'want'\n",
      " 'futures bybit' 'back' 'altsignals io' 'money' 'trx' 'so' 'active' 'open'\n",
      " 'community' 'currently' 'sale' 'plan' 'risk' 'group' 'and' 'even'\n",
      " 'cryptos' 'alt' 'big' 'watch' 'platform' 'trader' 'daily' 'project'\n",
      " 'bitmex btc' 'ethereum' 'best' 'low' 'going' 'hold' 'website' 'given'\n",
      " 'top' 'team' 'soon' 'xrp bch' 'people' 'well' 'pro' 'result' 'billion'\n",
      " 'to' 'mid' 'every' 'verifiedcrypto' 'access' 'btc buy' 'cap' 'huobi'\n",
      " 'contact' 'bearish' 'already' 'many' 'need' 'bybit btc'\n",
      " 'marketcap marketcap' 'active cryptos' 'strong' 'tg' 'dominance active'\n",
      " 'area' 'right' 'another' 'but' 'network' 'account' 'line' 'past' 'give'\n",
      " 'pip' 'chat' 'tp' 'total' 'keep' 'don' 'spot' 'look' 'hit profit'\n",
      " 'huobi pro' 'way' 'launch' 'gold' 'price reached' 'as' 'targets'\n",
      " 'binance bittrex' 'asset' 'mid term' 'twitter' 'mcap' 'offer' 'great'\n",
      " 'market cap' 'company' 'bch eos' 'looking' 'call' 'youtube' 'mcap change'\n",
      " 'volume change' 'cryptos volume' 'change volume' 'new' 'marketcap mcap'\n",
      " 'change bitcoin' 'check' 'huge' 'future' 'reach' 'world' 'bit' 'possible'\n",
      " 'wallet' 'sell binance' 'always' 'ico' 'range' 'moving' 'important'\n",
      " 'trend' 'live' 'message' 'point' 'everyone' 'million' 'position' 'end'\n",
      " 'bank' 'on' 'verifiedcryptotraders' 'breakout' 'opportunity' 'know'\n",
      " 'after' 'with' 'got' 'dominance volume' 'higher' 'let' 'bonus' 'digital'\n",
      " 'made' 'service' 'state' 'us' 'sell target' 'bsv' 'happy' 'r_o_d' 'share'\n",
      " 'yesterday' 'weekly' 'target stop' 'short term' 'there' 'user' 'come'\n",
      " 'admin' 'pump' 'gain' 'enjoy' 'much' 'bittrex kucoin' 'follow'\n",
      " 'minutes bittrex' 'april' 'here' 'investment' 'io join' 'based' 'payment'\n",
      " 'done' 'within' 'eth usdt' 'reward' 'of' 'how' 'become' 'event' 'however'\n",
      " 'crypto market' 'miss' 'report' 'full' 'help' 'per' 'nft' 'read'\n",
      " 'indicator' 'coming' 'signals' 'july' 'form' 'lifetime' 'altcoins'\n",
      " 'cryptocurrencies' 'say' 'bull' 'st' 'lower' 'what' 'june' 'ftx' 'fee'\n",
      " 'finance' 'run' 'major' 'binance kucoin' 'day' 'cap bitcoin' 'order'\n",
      " 'article' 'app' 'september' 'win' 'potential' 'wait' 'better' 'coinbase'\n",
      " 'bybit bitmex' 'october' 'expect' 'transaction' 'youtube watch' 'sure'\n",
      " 'xbt' 'tg tg' 'fund' 'key' 'ema' 'chance' 'altcoin' 'mycsupportbot'\n",
      " 'kucoin btc' 'stay' 'using' 'two' 'earn' 'not' 'august' 'currency' 'more'\n",
      " 'candle' 'put' 'luna' 'video' 'part' 'no' 'value' 'make' 'march' 'real'\n",
      " 'drop' 'think' 'code' 'hope' 'capital' 'gap' 'small' 'try' 'just'\n",
      " 'current state' 'marketcap market' 'ago' 'closed' 'portfolio' 'youtu'\n",
      " 'mean' 'making' 'coindesk' 'long term' 'use' 'yet' 'game' 'membership'\n",
      " 'safe' 'expected' 'holding' 'bittrex binance' 'till' 'status' 'alts'\n",
      " 'please' 'luna usdt' 'thing' 'information' 'lot' 'public' 'bottom'\n",
      " 'official' 'ltc usdt' 'dump' 'early' 'team_ucs' 'return' 'contract'\n",
      " 'available' 'usd all' 'supply' 'waiting' 'far' 'quick' 'second'\n",
      " 'investor' 'only' '__' 'block' 'bounce' 'private' 'defi' 'hard'\n",
      " 'successfully' 'cme' 'is' 'mining' 'ready' 'smart' 'accuracy'\n",
      " 'onwardbtcbot' 'november' 'nd' 'bch ltc' 'miota' 'groups' 'pay' 'data'\n",
      " 'eos ltc' 'weak' 'pm' 'valid' 'financial' 'fast' 'that' 'play' 'sl'\n",
      " 'said' 'test' 'decentralized' 'december' 'leverage price'\n",
      " 'kucoin binance' 'deribit' 'doge' 'sign' 'members' 'le' 'number'\n",
      " 'join vip']\n"
     ]
    }
   ],
   "source": [
    "vocab = vec.get_feature_names_out()\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print(topic_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample conversation\n",
    "convo = \"Yea this is definitely the case. They only started their crypto division in 2017. So plenty of capital to bail out their subsidiary. Now all eyes on that wallet to see where the eth moves.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:00<00:00, 34663.67it/s]\n"
     ]
    }
   ],
   "source": [
    "stemmed = []\n",
    "words = tokenizer.tokenize(convo)\n",
    "for word in tqdm(words):\n",
    "    word = re.sub(r'\\d+', '', word)\n",
    "    word = word.strip()\n",
    "    if word[:4] == 'box_' or word[:2] == '0x':\n",
    "        continue\n",
    "    if word not in ignore:\n",
    "        stemmed.append(stemmer.lemmatize(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crypto\n",
      "capital\n",
      "wallet\n",
      "eth\n"
     ]
    }
   ],
   "source": [
    "for word in stemmed: # print extracted keywords\n",
    "    for keyword in topic_words:\n",
    "        if word == keyword:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e73f90039056220150cf1d4e65e6306a9071453dfa618a459a84b4d9bee516f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
